---
title: "Dynamic Linear Regression"
author: "Lxy"
date: "November 4, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(fpp)
```

## Dynamic regression models

[^1]: Forecasting with cointegrated models is discussed in R. Harris and R. Sollis (2003). Applied Time Series Modelling and Forecasting. Chichester, UK: John Wiley & Sons.

We allow errors from the regression to contain autocorrelation
$$y_{t} = \beta_{0} + \beta_{1}x_{1,t} + ... + \beta_{k}x_{k,t} + n_{t}$$
$n_{t}$ then follows the ARIMA model. Example if it follows ARIMA(1,1,1), then
$$(1-\phi_{1}B)(1-B)n_{t} = (1+\theta_{1}B)e_{t}$$
where $e_{t}$ is a white noise series

### Estimation 

We try to minimise sum of squared $e_{t}$ values (equivalent to using MLE), NOT the $n_{t}$ values. IF NOT, some issues: 

* est. coeff $\hat{\beta_{0}}, ... \hat{\beta_{k}}$ no longer has best estimates
* statistical tests not correct
* AIC not a good guide to decide best model

In most cases *p*-values of coeff will be too small, resulting in predictor variables appearing to be important, also know as "spurious regression".

Check:

1. Stationarity for both forecast variable $y_{t}$ and predictors $x_{1,t}, ... , x_{k,t}$
    + unless non-stationary variables are co-integrated, i.e. linear combination between non stationary $y_{t}$ and predictors that is stationary [^1]

2. Try to use same level of differencing for variables. 
3. By differencing the ARIMA(1,1,1) error model above, we get ARMA errors as below.

$$y_{t}' = \beta_{0} + \beta_{1}x_{1,t}' + ... + \beta_{k}x_{k,t}' + n_{t}'$$
$$(1-\phi_{1}B)(1-B)n_{t}' = (1+\theta_{1}B)e_{t}$$

where $y_{t}' = y_{t} - y_{t-1}, x_{t,i}' = x_{t,i}-x_{t-1,i} and n_{t}' = n_{t}-n_{t-1}$

### Model Selection

To estimate the coeffs $\hat{\beta_{0}}, ... \hat{\beta_{k}}$, we began with a proxy model, i.e. AR(2) or ARIMA(2,0,0)(1,0,0)~m~ for seasonal data.

Steps:

1. Box-Cox transformation if required
2. Fit regression model with AR(2) for non-seasonal data or ARIMA(2,0,0)(1,0,0)m errors for seasonal data
3. calculate errors $n_{t}$ from the fitted regression model and identify appropriate ARMA model for errors
4. refit entire model using new ARMA model for errors
5. check if $e_{t}$ series looks like white noise
6. Select predictors based on lowest AIC

#### Example: relationship between personal consumption expenditure and income in USA, 1970 to 2010

```{r plot US consum vs income}
plot(usconsumption, xlab="Year",
     main="Quarterly changes in US consumption and personal income")

```

Data is considered stationary (percentage changes). So we first regress consuption on income assuming AR(2) errors.  
** Arima function fit for ARIMA errors if argument xreg is used. different from arima function **
** specify include.drift=TRUE to include constant in differenced model**

```{r fit AR(2) errors model with xreg consum}
fit <- Arima(usconsumption[,1], xreg=usconsumption[,2],
             order=c(2,0,0)) 
tsdisplay(arima.errors(fit), main="ARIMA errors")
auto.arima(usconsumption[,1], xreg=usconsumption[,2], ic="aicc")
```

ARIMA errors plot show possibility for MA(3) and AR(2). auto.arima function indicates ARIMA(1,0,2) has the lowest AICc value. Refit model with ARIMA errors as below.

```{r fit ARIMA(1,0,2) with xreg consum}
(fit2 <- Arima(usconsumption[,1], xreg=usconsumption[,2],
               order=c(1,0,2)))
```

A Ljung-Box test shows the residuals are uncorrelated.

```{r Ljung-Box test residuals}
Box.test(residuals(fit2),fitdf=5,lag=10,type="Ljung")
```

We do a forecast for the next 8 quarters, assuming income change is the same as last 40 years.

```{r forecast ARIMA model with xreg consum}
fcast <- forecast(fit2,xreg=rep(mean(usconsumption[,2]),8), h=8)
plot(fcast, main="Forecasts from regression with ARIMA(1,0,2) errors")
```

Prediction intervals are narrower than a normal ARIMA model because we explain more variation using the income predictor.

### Forecasting

There are two parts of inputs: regression and ARIMA part.
For the regression part, we need to know the future predictors
Note: Prediction intervals from regression intervals **DO NOT** take into account the uncertainty in the forecasts of the predictors.

2 ways of modelling a linear trend:
1. Deterministic Trend
    + $y_{t} = \beta_{0} + \beta_{1}t + n_{t}$ where $n_{t}$ is an ARMA process

2. Stochastic Trend
    + $y_{t} = \beta_{0} + \beta_{1}t + n_{t}$ where $n_{t}$ is an ARIMA process with d = 1.
    + After difference, $y_{t}' = \beta_{1} + n_{t}'$ where $n_{t}'$ is  an ARMA process
    + $y_{t} = y_{t-1} + \beta_{1} + n_{t}'$
    

#### Example: fit deterministic and stochastic trend model to total number of international visitors to Australia each year from 1980 to 2010

**Deterministic Trend**
```{r find model with determ trend}
auto.arima(austa,d=0,xreg=1:length(austa)) 
```
$$ y_{t} = 0.42 + 0.17t + n_{t} $$
$$ n_{t} = 1.04n_{t-1} - 0.34n_{t-2} + e_{t} $$
$$ e_{t} ~ NID(0, 0.025) $$

**Stochastic Trend**
```{r find model with stoch trend}
auto.arima(austa, d=1)
```
$$ y_{t} = 0.15t + n_{t} $$
$$ n_{t} = n_{t-1} + e_{t} $$
$$ e_{t} ~ NID(0, 0.032) $$

```{r fit and plot forecast of stoch and determ trend models}
fit1 <- Arima(austa, order=c(0,1,0), include.drift=TRUE)
fit2 <- Arima(austa, order=c(2,0,0), include.drift=TRUE)
par(mfrow=c(2,1))
plot(forecast(fit2), main="Forecasts from linear trend + AR(2) error",
  ylim=c(1,8))
plot(forecast(fit1), ylim=c(1,8))
```

Prediction intervals are much wider for stochastic trends as the errors are non-stationary.
interpretation of trend:
* deterministic trend: slope of trend remains fixed over time
* stochastic trend: slope of trend can change. Estimated growth is the average growth over the historical period. Allows for greater uncertainty in future growth

### Lagged predictors

Allow for lagged effects of the predictor, e.g. model for one predictor with lag k
$$ y_{t} = \beta_{0} + \gamma_{0}x_{t} + \gamma_{1}x_{t-1} + ... + \gamma_{k}x_{t-k} + n_{t} $$
where $n_{t}$ is an ARIMA process.
values of *k, p, q* can be selected using AIC.

#### Example: TV ads and insurance quotes. Find relationship between historical ads spent on quotes.

```{r create lagged data and find best model based on AIC}
plot(insurance, main="Insurance advertising and quotations", xlab="Year")

# Lagged predictors. Test 0, 1, 2 or 3 lags.
Advert <- cbind(insurance[,2],
 c(NA,insurance[1:39,2]),
 c(NA,NA,insurance[1:38,2]),
 c(NA,NA,NA,insurance[1:37,2]))
colnames(Advert) <- paste("AdLag",0:3,sep="")

# Choose optimal lag length for advertising based on AIC
# Restrict data so models use same fitting period
fit1 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1], d=0)
fit2 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:2], d=0)
fit3 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:3], d=0)
fit4 <- auto.arima(insurance[4:40,1], xreg=Advert[4:40,1:4], d=0)

# Best model fitted to all data (based on AICc)
# Refit using all data
fit <- auto.arima(insurance[,1], xreg=Advert[,1:2], d=0)
```

```{r}
fit
```

We are only considering historical ads spending up to 4 months. The model with lowest AICc highlights ads spending up to 2 months, and AR(3) errors.

$$ y_{t} = \beta_{0} + \gamma_{0}x_{t} + \gamma_{1}x_{t-1} + n_{t}$$
$$ n+{t} = \phi_{1}n_{t-1} + \phi_{2}n_{t-2} + \phi_{3}n_{t-3} + e_{t} $$

where $y_{t}$ is the number of quotes in month t, $x_{t}$ is the ads spending in month t.

**Forecast using hte model assuming ads spending is 8 per month.**

```{r}
fc8 <- forecast(fit, xreg=cbind(rep(8,20),c(Advert[40,1],rep(8,19))), h=20)
plot(fc8, main="Forecast quotes with advertising set to 8", ylab="Quotes")
```

